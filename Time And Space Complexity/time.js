<<<<<<< HEAD
// # â±ï¸ Time & Space Complexity â€“ Complete Detailed Notes

// ---

// ## 1ï¸âƒ£ Introduction

// In computer science, writing a correct program is not enough.  
// We must also write **efficient programs**.

// Efficiency depends on:
// - How fast a program runs â†’ **Time Complexity**
// - How much memory it uses â†’ **Space Complexity**

// Time and Space Complexity help us **analyze, compare, and optimize algorithms** without depending on hardware speed.

// ---

// ## 2ï¸âƒ£ What is Time Complexity?

// **Time Complexity** is a measure of how the execution time of an algorithm increases with the size of input.

// - It does NOT measure actual time (seconds)
// - It counts number of basic operations
// - It is represented using **Big-O notation**

// ### Example:
// If an algorithm takes more steps as input grows, it has higher time complexity.

// ---

// ## 3ï¸âƒ£ What is Space Complexity?

// **Space Complexity** is the amount of **extra memory** required by an algorithm during execution.

// It includes:
// - Variables
// - Arrays
// - Objects
// - Recursive call stack
// - Temporary data structures

// > Input space is not counted, only **extra space** is considered.

// ---

// ## 4ï¸âƒ£ Why Time & Space Complexity Are Important?

// - To choose the **best algorithm**
// - To reduce execution time
// - To reduce memory usage
// - To avoid **Time Limit Exceeded (TLE)** errors
// - Very important in **competitive programming, exams, and interviews**

// ---

// ## 5ï¸âƒ£ Asymptotic Notations

// Asymptotic notations describe the behavior of algorithms as input size becomes very large.

// ### Types:
// - **Big-O (O)** â†’ Worst Case
// - **Big-Theta (Î˜)** â†’ Average Case
// - **Big-Omega (Î©)** â†’ Best Case

// ðŸ‘‰ In practice, **Big-O is most commonly used**.

// ---

// ## 6ï¸âƒ£ Big-O Notation

// Big-O notation represents the **upper bound** of an algorithmâ€™s running time.

// It focuses on:
// - Worst-case performance
// - Growth rate of function
// - Dominant term only

// ---

// ## 7ï¸âƒ£ Common Time Complexities Table

// | Complexity | Name | Example |
// |---------|------|--------|
// | O(1) | Constant | Access array |
// | O(log n) | Logarithmic | Binary search |
// | O(âˆšn) | Square Root | Prime check |
// | O(n) | Linear | Array traversal |
// | O(n log n) | Linearithmic | Merge sort |
// | O(nÂ²) | Quadratic | Bubble sort |
// | O(nÂ³) | Cubic | Matrix multiplication |
// | O(2â¿) | Exponential | Fibonacci |
// | O(n!) | Factorial | Permutations |

// ---

// ## 8ï¸âƒ£ O(1) â€“ Constant Time Complexity

// ### Definition:
// The algorithm takes the **same time**, regardless of input size.

// ### Characteristics:
// - Fastest possible complexity
// - No loops depending on input

// ### Example:
// ```cpp
// int x = arr[10];

console.log("Accessing an element in an array is O(1) time complexity.");
=======
// # â±ï¸ Time & Space Complexity â€“ Complete Detailed Notes

// ---

// ## 1ï¸âƒ£ Introduction

// In computer science, writing a correct program is not enough.  
// We must also write **efficient programs**.

// Efficiency depends on:
// - How fast a program runs â†’ **Time Complexity**
// - How much memory it uses â†’ **Space Complexity**

// Time and Space Complexity help us **analyze, compare, and optimize algorithms** without depending on hardware speed.

// ---

// ## 2ï¸âƒ£ What is Time Complexity?

// **Time Complexity** is a measure of how the execution time of an algorithm increases with the size of input.

// - It does NOT measure actual time (seconds)
// - It counts number of basic operations
// - It is represented using **Big-O notation**

// ### Example:
// If an algorithm takes more steps as input grows, it has higher time complexity.

// ---

// ## 3ï¸âƒ£ What is Space Complexity?

// **Space Complexity** is the amount of **extra memory** required by an algorithm during execution.

// It includes:
// - Variables
// - Arrays
// - Objects
// - Recursive call stack
// - Temporary data structures

// > Input space is not counted, only **extra space** is considered.

// ---

// ## 4ï¸âƒ£ Why Time & Space Complexity Are Important?

// - To choose the **best algorithm**
// - To reduce execution time
// - To reduce memory usage
// - To avoid **Time Limit Exceeded (TLE)** errors
// - Very important in **competitive programming, exams, and interviews**

// ---

// ## 5ï¸âƒ£ Asymptotic Notations

// Asymptotic notations describe the behavior of algorithms as input size becomes very large.

// ### Types:
// - **Big-O (O)** â†’ Worst Case
// - **Big-Theta (Î˜)** â†’ Average Case
// - **Big-Omega (Î©)** â†’ Best Case

// ðŸ‘‰ In practice, **Big-O is most commonly used**.

// ---

// ## 6ï¸âƒ£ Big-O Notation

// Big-O notation represents the **upper bound** of an algorithmâ€™s running time.

// It focuses on:
// - Worst-case performance
// - Growth rate of function
// - Dominant term only

// ---

// ## 7ï¸âƒ£ Common Time Complexities Table

// | Complexity | Name | Example |
// |---------|------|--------|
// | O(1) | Constant | Access array |
// | O(log n) | Logarithmic | Binary search |
// | O(âˆšn) | Square Root | Prime check |
// | O(n) | Linear | Array traversal |
// | O(n log n) | Linearithmic | Merge sort |
// | O(nÂ²) | Quadratic | Bubble sort |
// | O(nÂ³) | Cubic | Matrix multiplication |
// | O(2â¿) | Exponential | Fibonacci |
// | O(n!) | Factorial | Permutations |

// ---

// ## 8ï¸âƒ£ O(1) â€“ Constant Time Complexity

// ### Definition:
// The algorithm takes the **same time**, regardless of input size.

// ### Characteristics:
// - Fastest possible complexity
// - No loops depending on input

// ### Example:
// ```cpp
// int x = arr[10];

console.log("Accessing an element in an array is O(1) time complexity.");
>>>>>>> f5f241b398a51c71173405e728ef865942cd7fdb
